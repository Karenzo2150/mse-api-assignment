{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02057ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (0.11.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pdfminer.six==20250506 in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (from pdfplumber) (20250506)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\evariste.manirumva\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy pdfplumber\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9c391b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_WORKSPACE = Path.cwd().parents[0]\n",
    "DIR_DATA = DIR_WORKSPACE / \"data\"\n",
    "DIR_REPORTS_CSV = DIR_DATA / \"mse-daily-data\"\n",
    "DIR_OUTPUT = DIR_DATA / \"combined_output_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f190ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (17872, 19)\n",
      "Combined CSV saved at: d:\\Documents\\AIMS_DSCBI_Training\\mse-api-assignment\\data\\combined_output_data\\combined_reports.csv\n"
     ]
    }
   ],
   "source": [
    "# Collect and combine all CSV files\n",
    "all_csv_files = DIR_REPORTS_CSV.glob(\"*.csv\")  # all CSVs in that directory\n",
    "df_list = [pd.read_csv(f) for f in all_csv_files]\n",
    "\n",
    "if df_list:  # make sure it's not empty\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    combined_df['counter_id'] = range(1, len(combined_df['counter_id']) + 1)\n",
    "    print(\"Combined shape:\", combined_df.shape)\n",
    "\n",
    "    # Save to a single CSV\n",
    "    output_file = DIR_OUTPUT / \"combined_reports.csv\"\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(\"Combined CSV saved at:\", output_file)\n",
    "else:\n",
    "    print(\"No CSV files found in\", DIR_REPORTS_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0ec5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head(100)\n",
    "combined_df.shape\n",
    "combined_df.info()\n",
    "combined_df.describe()\n",
    "combined_df['counter'].value_counts()\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c4a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined CSV file into a DataFrame\n",
    "combined_stock_df = pd.read_csv(output_file)\n",
    "print(combined_stock_df.head())\n",
    "print(combined_stock_df[\"counter\"].unique())\n",
    "\n",
    "company_map = {\n",
    "    \"AIRTEL\": \"AIRTEL MALAWI PLC\",\n",
    "    \"BHL\": \"BLANTYRE HOTELS PLC\",\n",
    "    \"FDHB\": \"FDH BANK PLC\",\n",
    "    \"FMBCH\": \"FMB CAPITAL HOLDINGS PLC\",\n",
    "    \"ICON\": \"ICON PROPERTIES PLC\",\n",
    "    \"ILLOVO\": \"ILLOVO SUGAR MALAWI PLC\",\n",
    "    \"MPICO\": \"MPICO PLC\",\n",
    "    \"NBM\": \"NATIONAL BANK OF MALAWI\",\n",
    "    \"NBS\": \"NBS BANK PLC\",\n",
    "    \"NICO\": \"NICO HOLDINGS PLC\",\n",
    "    \"NITL\": \"NATIONAL INVESTMENT TRUST PLC\",\n",
    "    \"OMU\": \"OLD MUTUAL LIMITED\",\n",
    "    \"PCL\": \"PRESS CORPORATION PLC\",\n",
    "    \"STANDARD\": \"STANDARD BANK MALAWI PLC\",\n",
    "    \"SUNBIRD\": \"SUNBIRD TOURISM PLC\",\n",
    "    \"TNM\": \"TELEKOM NETWORKS MALAWI PLC\"\n",
    "}\n",
    "# Add a new column with the full name\n",
    "combined_stock_df[\"name\"] = combined_stock_df[\"counter\"].map(company_map)\n",
    "combined_stock_df = combined_stock_df.rename(columns={\n",
    "    \"counter\": \"ticker\",\n",
    "    \"trade_date\": \"date_listed\",\n",
    "    \"buy_price\": \"listing_price\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0898b4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost 5432 mse_database postgres\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PGHOST = os.getenv(\"PGHOST\", \"\").strip()\n",
    "PGPORT = os.getenv(\"PGPORT\", \"\").strip()\n",
    "PGPORT = int(''.join(filter(str.isdigit, PGPORT))) if PGPORT else 5432\n",
    "PGDATABASE = os.getenv(\"PGDATABASE\", \"\").strip()\n",
    "PGUSER = os.getenv(\"PGUSER\", \"\").strip()\n",
    "\n",
    "# Optional: print to confirm\n",
    "print(PGHOST, PGPORT, PGDATABASE, PGUSER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85050f9",
   "metadata": {},
   "source": [
    "# sql tools for create and link database and tables\n",
    "D:\\Documents\\AIMS_DSCBI_Training\\mse-api-assignment>psql -U postgres\n",
    "CREATE DATABASE mse_database; # Create a database\n",
    "postgres=# \\c mse_database # connect to database or postgres=# \\connect mse_database\n",
    "mse_database=# \\dt # check content(tables) of the db\n",
    "## Create tables under database (mse_database)\n",
    "CREATE TABLE IF NOT EXISTS counters (\n",
    "    counter_id TEXT PRIMARY KEY,\n",
    "    ticker TEXT NOT NULL,\n",
    "    name TEXT NOT NULL,\n",
    "    date_listed DATE,\n",
    "    listing_price NUMERIC(10,2)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS prices_daily (\n",
    "    counter_id TEXT REFERENCES counters(counter_id),\n",
    "    trade_date DATE,\n",
    "    open_mwk NUMERIC(10,2),\n",
    "    high_mwk NUMERIC(10,2),\n",
    "    low_mwk NUMERIC(10,2),\n",
    "    close_mwk NUMERIC(10,2),\n",
    "    volume BIGINT,\n",
    "    PRIMARY KEY (counter_id,Â trade_date)\n",
    ");\n",
    "# populate the tables(counters) of database \n",
    "INSERT INTO counters (counter_id, ticker, name, date_listed, listing_price)\n",
    "OVERRIDING SYSTEM VALUE\n",
    "VALUES\n",
    "  (1,  'AIRTEL',   'Airtel Malawi plc',                          '2020-02-24', 12.69),\n",
    "  (2,  'BHL',      'Blantyre Hotels plc',                        '1997-03-25',  0.84),\n",
    "  (3,  'FDHB',     'FDH Bank plc',                               '2020-08-03', 10.00),\n",
    "  (4,  'FMBCH',    'FMB Capital Holdings plc',                   '2017-09-18', 45.01),\n",
    "  (5,  'ICON',     'Icon Properties plc',                        '2019-01-21',  8.75),\n",
    "  (6,  'ILLOVO',   'Illovo Sugar Malawi plc',                    '1997-11-10',  2.25),\n",
    "  (7,  'MPICO',    'Malawi Property Investment Company plc',     '2007-08-28',  1.00),\n",
    "  (8,  'NBM',      'National Bank of Malawi plc',                '2000-08-21',  4.00),\n",
    "  (9,  'NBS',      'NBS Bank plc',                               '2007-06-25',  2.60),\n",
    "  (10, 'NICO',     'NICO Holdings plc',                          '1996-11-11',  2.00),\n",
    "  (11, 'NITL',     'National Investment Trust plc',              '2005-03-21',  2.65),\n",
    "  (12, 'OMU',      'Old Mutual Limited',                         '2018-06-26', 1580.22),\n",
    "  (13, 'PCL',      'Press Corporation plc',                      '1998-09-09', 14.89),\n",
    "  (14, 'STANDARD', 'Standard Bank Malawi plc',                   '1998-06-29',  3.25),\n",
    "  (15, 'SUNBIRD',  'Sunbird Tourism plc',                        '2002-08-21',  2.60),\n",
    "  (16, 'TNM',      'Telekom Networks Malawi plc',                '2008-11-25',  5.00);\n",
    "## check content of counter table\n",
    "  mse_database=# \\d counters\n",
    "## drop tables from database\n",
    "mse_database=# DROP TABLE counter CASCADE; # drop all relations/references\n",
    "mse_database=# DROP TABLE counter;\n",
    "  \n",
    "## To browse the data from table counters\n",
    "mse_database=# SELECT * FROM counters;\n",
    "mse_database-# limit(10);\n",
    "mse_database-# SELECT counter_id, trade_date FROM counters;\n",
    "mse_database=# \\d+ prices_daily #check general information of table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242e33d",
   "metadata": {},
   "source": [
    "## Update existing counter_id values in counters table\n",
    "UPDATE counters SET counter_id = 'MWAIRT001156' WHERE ticker = 'AIRTEL';\n",
    "UPDATE counters SET counter_id = 'MWBHL0010029' WHERE ticker = 'BHL';\n",
    "UPDATE counters SET counter_id = 'MWFDHB001166' WHERE ticker = 'FDH';\n",
    "UPDATE counters SET counter_id = 'MWFMB0010138' WHERE ticker = 'FMB';\n",
    "UPDATE counters SET counter_id = 'MWICON001146' WHERE ticker = 'ICON';\n",
    "UPDATE counters SET counter_id = 'MWILLV010032' WHERE ticker = 'ILLVO';\n",
    "UPDATE counters SET counter_id = 'MWMPI0010116' WHERE ticker = 'MPI';\n",
    "UPDATE counters SET counter_id = 'MWNBM0010074' WHERE ticker = 'NBM';\n",
    "UPDATE counters SET counter_id = 'MWNBS0010105' WHERE ticker = 'NBS';\n",
    "UPDATE counters SET counter_id = 'MWNICO010014' WHERE ticker = 'NICO';\n",
    "UPDATE counters SET counter_id = 'MWNITL010091' WHERE ticker = 'NITL';\n",
    "UPDATE counters SET counter_id = 'ZAE000255360' WHERE ticker = 'OMU';\n",
    "UPDATE counters SET counter_id = 'MWPCL0010053' WHERE ticker = 'PCL';\n",
    "UPDATE counters SET counter_id = 'MWSTD0010041' WHERE ticker = 'STANDARD';\n",
    "UPDATE counters SET counter_id = 'MWSTL0010085' WHERE ticker = 'SUNBIRD';\n",
    "UPDATE counters SET counter_id = 'MWTNM0010126' WHERE ticker = 'TNM';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf72bb0",
   "metadata": {},
   "source": [
    "\n",
    "Step 1: Drop existing table (optional)\n",
    "DROP TABLE IF EXISTS prices_daily;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS prices_daily (\n",
    "    counter_id BIGINT,\n",
    "    counter TEXT,\n",
    "    daily_range_high NUMERIC(15,2),\n",
    "    daily_range_low NUMERIC(15,2),\n",
    "    buy_price NUMERIC(15,2),\n",
    "    sell_price NUMERIC(15,2),\n",
    "    previous_closing_price NUMERIC(15,2),\n",
    "    today_closing_price NUMERIC(15,2),\n",
    "    volume_traded NUMERIC(15,2),\n",
    "    dividend_mk NUMERIC(15,2),\n",
    "    dividend_yield_pct NUMERIC(15,2),\n",
    "    earnings_yield_pct NUMERIC(15,2),\n",
    "    pe_ratio NUMERIC(15,2),\n",
    "    pbv_ratio NUMERIC(15,2),\n",
    "    market_capitalization_mkmn NUMERIC(20,2),\n",
    "    profit_after_tax_mkmn NUMERIC(20,2),\n",
    "    num_shares_issue NUMERIC(20,2),\n",
    "    trade_date DATE,\n",
    "    print_time TEXT,\n",
    "    PRIMARY KEY (counter_id, trade_date)\n",
    ");\n",
    "## add variable column into table\n",
    "ALTER TABLE prices_daily\n",
    "ADD COLUMN sell_price NUMERIC(10,2);\n",
    "\n",
    "# link whole csv file to sql database directly\n",
    "COPY prices_daily FROM 'D:\\\\Documents\\\\AIMS_DSCBI_Training\\\\mse-api-assignment\\\\data\\\\combined_output_data\\\\combined_reports.csv' DELIMITER ',' CSV HEADER;\n",
    "\n",
    "# link csv file to sql database (directly import specific variables)\n",
    "\\copy prices_daily(counter_id, counter, daily_range_high, daily_range_low, buy_price, sell_price, previous_closing_price, today_closing_price, volume_traded, dividend_mk, dividend_yield_pct, earnings_yield_pct, pe_ratio, pbv_ratio, market_capitalization_mkmn, profit_after_tax_mkmn, num_shares_issue, trade_date, print_time) FROM 'D:/Documents/AIMS_DSCBI_Training/mse-api-assignment/data combined_output_data/combined_reports.csv' CSV HEADER;\n",
    "\n",
    "\n",
    "### change the decimal formats of figures\n",
    "ALTER TABLE prices_daily\n",
    "ALTER COLUMN column volume_traded TYPE NUMERIC(15,2);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b8c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Read CSV \n",
    "df = pd.read_csv(r\"D:\\Documents\\AIMS_DSCBI_Training\\mse-api-assignment\\data\\misc\\listing.csv\")\n",
    "\n",
    "# # Convert to datetime type (from DD-MM-YY to YYYY-MM-DD)\n",
    "df['date_listed'] = pd.to_datetime(df['date_listed'], errors='coerce')\n",
    "df['date_listed'] = df['date_listed'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Create PostgreSQL connection\n",
    "## Create SQLAlchemy engine (no password needed for local connections)\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:admin@localhost:5432/mse_database\")\n",
    "# Write to SQL\n",
    "mse_counters = df.to_sql(\"tickers\", engine, if_exists=\"replace\", index=False)\n",
    "print(\"â Data successfully written to SQL table tickers\")\n",
    "print(mse_counters)\n",
    "\n",
    "# Verify by querying the table\n",
    "with engine.connect() as conn:\n",
    "     result = conn.execute(text(\"SELECT * FROM tickers LIMIT 5;\"))\n",
    "     for row in result:\n",
    "         print(row)\n",
    "         print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "909182be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     counter_id   ticker                      name date_listed  listing_price\n",
      "0  MWAIRT001156  AIRTELL         AIRTEL MALAWI PLC  2020-02-24          12.69\n",
      "1  MWBHL0010029      BHL       BLANTYRE HOTELS PLC  1997-03-25           0.84\n",
      "2  MWFDHB001166     FDHB              FDH BANK PLC  2020-08-03          10.00\n",
      "3  MWFMB0010138    FMBCH  FMB CAPITAL HOLDINGS PLC  2017-09-18          45.01\n",
      "4  MWICON001146     ICON       ICON PROPERTIES PLC  2019-01-21           8.75\n"
     ]
    }
   ],
   "source": [
    "# read table from sql database as dataframe\n",
    "df = pd.read_sql(\"SELECT * FROM tickers\", engine)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03fdd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter_id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "      <th>date_listed</th>\n",
       "      <th>listing_price</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MWAIRT001156</td>\n",
       "      <td>AIRTELL</td>\n",
       "      <td>AIRTEL MALAWI PLC</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>12.69</td>\n",
       "      <td>Telecommunication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MWBHL0010029</td>\n",
       "      <td>BHL</td>\n",
       "      <td>BLANTYRE HOTELS PLC</td>\n",
       "      <td>1997-03-25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>Tourism and Hospitality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MWFDHB001166</td>\n",
       "      <td>FDHB</td>\n",
       "      <td>FDH BANK PLC</td>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Banking and Financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MWFMB0010138</td>\n",
       "      <td>FMBCH</td>\n",
       "      <td>FMB CAPITAL HOLDINGS PLC</td>\n",
       "      <td>2017-09-18</td>\n",
       "      <td>45.01</td>\n",
       "      <td>Capital &amp; Stock Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MWICON001146</td>\n",
       "      <td>ICON</td>\n",
       "      <td>ICON PROPERTIES PLC</td>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>8.75</td>\n",
       "      <td>Real Estate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     counter_id   ticker                      name date_listed  listing_price  \\\n",
       "0  MWAIRT001156  AIRTELL         AIRTEL MALAWI PLC  2020-02-24          12.69   \n",
       "1  MWBHL0010029      BHL       BLANTYRE HOTELS PLC  1997-03-25           0.84   \n",
       "2  MWFDHB001166     FDHB              FDH BANK PLC  2020-08-03          10.00   \n",
       "3  MWFMB0010138    FMBCH  FMB CAPITAL HOLDINGS PLC  2017-09-18          45.01   \n",
       "4  MWICON001146     ICON       ICON PROPERTIES PLC  2019-01-21           8.75   \n",
       "\n",
       "                    Sector  \n",
       "0        Telecommunication  \n",
       "1  Tourism and Hospitality  \n",
       "2    Banking and Financial  \n",
       "3   Capital & Stock Market  \n",
       "4              Real Estate  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify sectors based on company names\n",
    "# add a new column 'Sector' in the database (tickers) based on the company name\n",
    "\n",
    "Sector = []\n",
    "for x in df[\"name\"].values:\n",
    "    name = x.upper()  # Convert to uppercase for case-insensitive matching\n",
    "    if re.findall(\"BANK\", name):\n",
    "        Sector.append(\"Banking and Financial\")\n",
    "    elif re.findall(\"HOTELS\", name):\n",
    "        Sector.append(\"Tourism and Hospitality\")\n",
    "    elif re.findall(\"HOLDING\", name):\n",
    "        Sector.append(\"Capital & Stock Market\")\n",
    "    elif re.findall(\"AIRTEL\", name):\n",
    "        Sector.append(\"Telecommunication\")\n",
    "    elif re.findall(\"SUGAR\", name):\n",
    "        Sector.append(\"Manufacturing Industry\")\n",
    "    elif re.findall(\"NETWORKS\", name):\n",
    "        Sector.append(\"Telecommunication\")\n",
    "    elif re.findall(\"PRESS\", name):\n",
    "        Sector.append(\"Media\")\n",
    "    elif re.findall(\"MUTUAL\", name):\n",
    "        Sector.append(\"Insurance\")\n",
    "    elif re.findall(\"PROPERTIES\", name):\n",
    "        Sector.append(\"Real Estate\")\n",
    "    elif re.findall(\"TOURISM\", name):\n",
    "        Sector.append(\"Tourism\")\n",
    "    else:\n",
    "        Sector.append(\"Not Classified\")  # Default value if no match found\n",
    "\n",
    "df[\"Sector\"] = Sector\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7010da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"ALTER TABLE tickers ADD COLUMN IF NOT EXISTS sector TEXT;\"))\n",
    "    conn.commit()\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for _, row in df.iterrows():\n",
    "        conn.execute(\n",
    "            text(\"UPDATE tickers SET sector = :sector WHERE ticker = :ticker\"),\n",
    "            {\"sector\": row[\"Sector\"], \"ticker\": row[\"ticker\"]}\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386807d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export the updated dataframe back to the sql table\n",
    "df.to_sql(\"tickers\", engine, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e88f5a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872\n",
      "â Data successfully written to SQL table 'daily_prices'\n"
     ]
    }
   ],
   "source": [
    "# Read CSV \n",
    "df = pd.read_csv(r\"D:\\Documents\\AIMS_DSCBI_Training\\mse-api-assignment\\data\\combined_output_data\\combined_reports.csv\")\n",
    "# Convert to datetime type (from DD-MM-YY to YYYY-MM-DD)\n",
    "\n",
    "headers_vars = [\n",
    "    'counter_id', 'counter', 'daily_range_high', 'daily_range_low', 'buy_price',\n",
    "    'sell_price', 'previous_closing_price', 'today_closing_price', 'volume_traded', 'dividend_mk',\n",
    "    'dividend_yield_pct', 'earnings_yield_pct', 'pe_ratio', 'pbv_ratio',\n",
    "    'market_capitalization_mkmn', 'profit_after_tax_mkmn', 'num_shares_issue',\n",
    "    'trade_date', 'print_time']\n",
    "\n",
    "df = df[headers_vars]\n",
    "\n",
    "# Create PostgreSQL connection\n",
    "## Create SQLAlchemy engine (no password needed for local connections)\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:admin@localhost:5432/mse_database\")\n",
    "\n",
    "# Write to SQL\n",
    "mse_dailyPrices = df.to_sql(\"daily_prices\", engine, if_exists=\"replace\", index=False)\n",
    "print(mse_dailyPrices)\n",
    "print(\"â Data successfully written to SQL table 'daily_prices'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a0d17b",
   "metadata": {},
   "source": [
    "# Week 3: API Development\n",
    "** Implement all 3-5 required API endpoints\n",
    "** Add input validation using Pydantic models\n",
    "** Add query parameters for filtering\n",
    "\n",
    "### create and activate a virtual environment \n",
    "** python -m venv venv\n",
    "** .\\venv\\Scripts\\activate\n",
    "## install required packages\n",
    "** pip install -r requirements.txt\n",
    "## run py.script\n",
    "** (venv) D:\\Documents\\AIMS_DSCBI_Training\\mse-api-assignment>python -m uvicorn api_access:app --reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe7d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required packages\n",
    "import os\n",
    "from typing import Optional, List\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from fastapi import FastAPI, Query, Path, HTTPException\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "load_dotenv()\n",
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef4035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# RETURNING DATA FROM POSTGRESQL MSE_DATABASE\n",
    "# =========================================================\n",
    "\n",
    "# =============================================================\n",
    "# Load environment variables from .env file\n",
    "# =============================================================\n",
    "load_dotenv()\n",
    "# Get database connection details from environment variables\n",
    "PGHOST = os.getenv(\"PGHOST\", \"\").strip()\n",
    "PGPORT = os.getenv(\"PGPORT\", \"\").strip()\n",
    "PGPORT = int(''.join(filter(str.isdigit, PGPORT))) if PGPORT else 5432\n",
    "PGDATABASE = os.getenv(\"PGDATABASE\", \"\").strip()\n",
    "PGUSER = os.getenv(\"PGUSER\", \"\").strip()\n",
    "\n",
    "# =============================================================\n",
    "# HELPER FUNCTION TO CONNECT QUERY to sql database\n",
    "# =============================================================\n",
    "def run_query(sql: str, params: tuple = ()):\n",
    "    conn = psycopg2.connect(\n",
    "        host=PGHOST,\n",
    "        port=PGPORT,\n",
    "        dbname=PGDATABASE,\n",
    "        user=PGUSER,  \n",
    "    )\n",
    "    try:\n",
    "        df = pd.read_sql(sql, conn, params=params)\n",
    "        df = df.replace({np.nan: None, np.inf: None, -np.inf: None}) # convert NaN to none\n",
    "    finally:\n",
    "        conn.close()\n",
    "    return df.to_dict(orient = \"records\")\n",
    "\n",
    "# =============================================================\n",
    "# set ENDPOINTS and use app (fastAPI) to create a link form endpoints and convert sql database and retrieve API data\n",
    "# ===========================================================================================\n",
    "\n",
    "@app.get(\"/\")\n",
    "def Home():\n",
    "    return {\"message\":\"WELCOME TO MALAWI STOCK EXCHANGE DATABASE\"}\n",
    "\n",
    "@app.get(\"/companies\")\n",
    "def companies():\n",
    "    sql = \"SELECT * FROM tickers\"\n",
    "    return run_query(sql)\n",
    "\n",
    "# Get companies by sector\n",
    "@app.get(\"/companies/{sector}\")\n",
    "def get_companies(sector: str):\n",
    "    \"\"\"These are all company related data including counter_id, counter, listing price and Listing date\n",
    "    To retrieve the sector related info, plase do the following....\n",
    "    Company/sector=?\"\"\"\n",
    "\n",
    "  # Get all API from tickers database\n",
    "    sql = 'SELECT * FROM tickers WHERE LOWER(\"Sector\") = %s'\n",
    "    return run_query(sql, (sector.lower(),))\n",
    "    \n",
    "@app.get(\"/companies/{counter}\")\n",
    "def get_company_prices(counter: str):\n",
    "    sql = \"\"\"\n",
    "    SELECT\n",
    "        t.counter,\n",
    "        t.name,\n",
    "        t.\"Sector\",\n",
    "        t.\"Date Listed\",\n",
    "        COUNT(d.counter_id) AS price_entries,\n",
    "        d.counter_id AS price_counter_id\n",
    "    FROM tickers AS t\n",
    "    LEFT JOIN Daily_prices AS d \n",
    "        ON t.counter_id = d.counter_id\n",
    "    WHERE LOWER(t.counter) = LOWER(%s)\n",
    "    GROUP BY\n",
    "        t.counter,\n",
    "        t.name,\n",
    "        t.\"Sector\",\n",
    "        t.\"Date Listed\"\n",
    "    LIMIT 50;\n",
    "    \"\"\"\n",
    "    return run_query(sql, (counter,))\n",
    "\n",
    "@app.get(\"/daily_prices/{counter}\")\n",
    "def get_counter(counter: str):\n",
    "    sql = \"\"\"\n",
    "    SELECT\n",
    "        t.counter_id\n",
    "        t.counter,\n",
    "        t.\"daily_range_high\",\n",
    "        t.\"daily_range_low\",\n",
    "        t.\"buy_price\",\n",
    "        t.\"sell_price\",\n",
    "        t.\"previous_closing_price\",\n",
    "        t.\"today_closing_price\",\n",
    "        t.\"volume_traded\",\n",
    "        COUNT(d.counter_id) AS price_entries,\n",
    "        d.counter_id AS price_counter_id\n",
    "    FROM daily_prices AS t\n",
    "    LEFT JOIN Daily_prices AS d \n",
    "        ON t.counter_id = d.counter_id\n",
    "    WHERE LOWER(t.counter) = LOWER(%s)\n",
    "    GROUP BY\n",
    "        t.counter_id,\n",
    "        t.counter,\n",
    "    LIMIT 50;\n",
    "    \"\"\"\n",
    "    return run_query(sql, (counter,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
